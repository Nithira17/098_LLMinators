{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaveenSanjaya/Right-Vote/blob/main/Social_Media_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "296aa3df",
      "metadata": {
        "id": "296aa3df"
      },
      "source": [
        "### Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a7dc7a",
      "metadata": {
        "id": "c9a7dc7a"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Twitter API credentials\n",
        "API_KEY = 'MCu2BiFyXXXXXXX'\n",
        "API_SECRET_KEY = 'Cl8FYiqoVl82KyXXXXXXXXXX'\n",
        "BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAXXXXXXX'\n",
        "ACCESS_TOKEN = '1709435XXXXXXXX'\n",
        "ACCESS_TOKEN_SECRET = 'Lp50yuMNJjg5SDZXXXXXXXX'\n",
        "\n",
        "# Set up Twitter API client\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "# Initialize sentiment analysis model and tokenizer\n",
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
        "\n",
        "# Labels for sentiment analysis\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "def preprocess_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Preprocess the tweet by replacing mentions and URLs with placeholders.\n",
        "    \"\"\"\n",
        "    tweet_words = []\n",
        "    for word in tweet.split(' '):\n",
        "        if word.startswith('@') and len(word) > 1:\n",
        "            word = '@user'\n",
        "        elif word.startswith('http'):\n",
        "            word = \"http\"\n",
        "        tweet_words.append(word)\n",
        "    return \" \".join(tweet_words)\n",
        "\n",
        "def fetch_tweets(query, max_results=100):\n",
        "    \"\"\"\n",
        "    Fetch recent tweets containing the specified query.\n",
        "    \"\"\"\n",
        "    tweet_data = []\n",
        "    try:\n",
        "        tweets = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=['created_at', 'text'])\n",
        "        if tweets.data:\n",
        "            for tweet in tweets.data:\n",
        "                tweet_data.append({\n",
        "                    'created_at': tweet.created_at,\n",
        "                    'text': tweet.text\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching tweets: {e}\")\n",
        "    return tweet_data\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyze the sentiment of the given text using the pre-trained model.\n",
        "    \"\"\"\n",
        "    tweet_proc = preprocess_tweet(text)\n",
        "    encoded_tweet = tokenizer(tweet_proc, return_tensors='tf')\n",
        "    output = model(**encoded_tweet)\n",
        "    scores = output[0][0].numpy()\n",
        "    scores = softmax(scores)\n",
        "    return dict(zip(labels, scores))\n",
        "\n",
        "def plot_sentiment_distribution(sentiment_counts):\n",
        "    \"\"\"\n",
        "    Plot a bar chart of sentiment distribution.\n",
        "    \"\"\"\n",
        "    sentiments = list(sentiment_counts.keys())\n",
        "    counts = list(sentiment_counts.values())\n",
        "    plt.bar(sentiments, counts, color=['red', 'gray', 'green'])\n",
        "    plt.xlabel('Sentiment')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Sentiment Distribution')\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Example candidate names\n",
        "    candidates = [\"Sajith Premadasa\", \"Ranil Wickremesinghe\", \"Anura Kumara\"]\n",
        "\n",
        "    all_tweet_data = []\n",
        "\n",
        "    for candidate in candidates:\n",
        "        print(f\"Fetching tweets for {candidate}...\")\n",
        "        tweets = fetch_tweets(candidate, max_results=100)\n",
        "        for tweet in tweets:\n",
        "            tweet['candidate'] = candidate\n",
        "            all_tweet_data.append(tweet)\n",
        "\n",
        "    # Convert tweet data to DataFrame\n",
        "    df = pd.DataFrame(all_tweet_data)\n",
        "\n",
        "    # Analyze sentiment for each tweet\n",
        "    sentiment_counts = {label: 0 for label in labels}\n",
        "\n",
        "    for text in df['text']:\n",
        "        sentiment = analyze_sentiment(text)\n",
        "        for label, score in sentiment.items():\n",
        "            sentiment_counts[label] += score\n",
        "\n",
        "    # Print sentiment distribution\n",
        "    print(\"Sentiment Distribution:\")\n",
        "    for label, count in sentiment_counts.items():\n",
        "        print(f\"{label}: {count}\")\n",
        "\n",
        "    # Plot sentiment distribution\n",
        "    plot_sentiment_distribution(sentiment_counts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815021d8",
      "metadata": {
        "id": "815021d8"
      },
      "source": [
        "### Facebook Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb529b29",
      "metadata": {
        "id": "cb529b29"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "# Facebook API credentials\n",
        "ACCESS_TOKEN = 'EAAjjdeAxAF1eT5ZBbibXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
        "PAGE_ID = 'XXXXXXXXXXXXX'\n",
        "\n",
        "# Initialize sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline('sentiment-analysis')\n",
        "\n",
        "def fetch_facebook_posts(page_id, access_token, limit=10):\n",
        "    \"\"\"\n",
        "    Fetch recent posts from a Facebook page.\n",
        "    \"\"\"\n",
        "    url = f'https://graph.facebook.com/{page_id}/posts'\n",
        "    params = {\n",
        "        'access_token': access_token,\n",
        "        'limit': limit,\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    response.raise_for_status()\n",
        "    return response.json().get('data', [])\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyze the sentiment of the given text using Hugging Face's sentiment analysis model.\n",
        "    \"\"\"\n",
        "    return sentiment_pipeline(text)\n",
        "\n",
        "def main():\n",
        "    # Fetch recent posts\n",
        "    posts = fetch_facebook_posts(PAGE_ID, ACCESS_TOKEN, limit=5)\n",
        "\n",
        "    if not posts:\n",
        "        print(\"No posts found.\")\n",
        "        return\n",
        "\n",
        "    # Analyze sentiment for each post\n",
        "    for post in posts:\n",
        "        post_message = post.get('message', '')\n",
        "        if post_message:\n",
        "            sentiment = analyze_sentiment(post_message)\n",
        "            print(f\"Post: {post_message}\")\n",
        "            print(f\"Sentiment: {sentiment[0]['label']} (Confidence: {sentiment[0]['score']:.2f})\")\n",
        "            print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}